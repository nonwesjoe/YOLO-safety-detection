# YOLO Safety Gear Detection

This project utilizes a YOLO (You Only Look Once) object detection model to identify whether individuals in an image are wearing safety gear, specifically hats (helmets) and vests.

The model is built upon the [Ultralytics](https://ultralytics.com/) framework and is configured to detect the following five classes:
- `hat`: A person wearing a safety helmet.
- `nohat`: A person not wearing a safety helmet.
- `novest`: A person not wearing a safety vest.
- `person`: A person detected.
- `vest`: A person wearing a safety vest.

## How It Works

The `infer.py` script loads a pre-trained YOLO model (`.pt` file), performs inference on a specified input image (`test.jpg`), and saves the resulting image with bounding boxes and labels as `predicted.jpg`.

## Setup and Installation

1.  **Clone the repository:**
    ```bash
    git clone <your-repository-url>
    cd yolo_safety
    ```

2.  **Create a Python virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3.  **Install the required dependencies:**
    The core dependencies are `ultralytics` and `opencv-python`. You can install them using pip:
    ```bash
    pip install ultralytics opencv-python
    ```

## Usage

1.  **Place your pre-trained model:**
    The script `infer.py` expects a model file. Make sure to download the model file (e.g., `yolo11m-wide-viewer.pt`) and update its path in the script. For better project structure, it's recommended to create a `weights` directory for your models.

    Modify this line in `infer.py` to point to your model's location:
    ```python
    model = YOLO(r"path/to/your/model.pt")
    ```

2.  **Prepare your input image:**
    Place the image you want to analyze in the project's root directory and name it `test.jpg`, or update the path in `infer.py`:
    ```python
    img = r"path/to/your/image.jpg"
    ```

3.  **Run the inference script:**
    ```bash
    python infer.py
    ```

4.  **View the output:**
    - The script will generate an image named `predicted.jpg` in the root directory, showing the original image with detection boxes and labels.
    - An OpenCV window will also pop up to display the result live. Press any key to close it.

## File Descriptions

-   **`infer.py`**: The main Python script to run the object detection inference.
-   **`config.yaml`**: Configuration file for training the YOLO model. It contains hyperparameters like learning rate, batch size, and number of epochs.
-   **`data.yaml`**: Dataset configuration file. It defines the class names, the number of classes, and the paths to the training and validation data.
-   **`test.jpg`**: An example input image for testing the model.
-   **`predicted.jpg`**: The output image generated by `infer.py` after detection.
-   **`README.md`**: This file.

## Training (Optional)

This repository is also set up for training your own model.

1.  **Organize your dataset:**
    According to `data.yaml`, your dataset should be structured as follows:
    ```
    dataset/
    ├── train/
    │   ├── images/
    │   └── labels/
    └── val/
        ├── images/
        └── labels/
    ```

2.  **Update `data.yaml`:**
    Ensure the `path`, `train`, and `val` fields in `data.yaml` correctly point to your dataset directories.

3.  **Start training:**
    You can start the training process using the Ultralytics CLI or a custom Python script, loading the `config.yaml` and `data.yaml` files.

## License

This project is unlicensed. You are free to use, modify, and distribute it. Consider adding an [open-source license](https://choosealicense.com/) like MIT or Apache 2.0 if you plan to share it widely.
